{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from copy import deepcopy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of columns in csv file\n",
    "columns = ['TestSubject', 'Event', 'TimeStamp', 'Duration', 'Location',\n",
    "          'GameTime', 'Target', 'HowIsItGoingLikert', 'ProgressPlanSummary',\n",
    "          'SolutionApproachSummary', 'DifferentProblemApproachSummary',\n",
    "          'Name', 'Title', 'NPC', 'NpcSpokeCount', 'ConceptMatrixEditCount',\n",
    "          'ConceptMatrixAnsweredCorrectly', 'ObjectScanned', 'TestingFor',\n",
    "          'ReasonForTesting', 'TotalFieldsModified', 'WorksheetSubmitResult']\n",
    "\n",
    "# Order of columns in activity summary csv file\n",
    "activity_columns = ['TestSubject', 'ActivityUri', 'ActivityStarts', 'ActivityRestarts',\n",
    "                    'Age', 'Gender', 'Race', 'VideoGamePlayingFrequency', \n",
    "                    'VideoGamePlayingSkill', 'VideoGamePlayingHoursPerWeek', 'VideoGamesPlayed',\n",
    "                    'PreTestScore', 'PostTestScore', 'LearningGain', 'MysterySolved', \n",
    "                    'TotalPromptOpens', 'MeanPromptResponseDuration', 'MeanHowIsItGoingLikert',\n",
    "                    'TotalWorksheetSubmits', 'SolutionDisease', 'InfectionType', 'SolutionObject',\n",
    "                    'SolutionTreatment', 'StartTime', 'StopTime', 'Duration', 'PlotPointsActivated',\n",
    "                    'TotalComplexTextDuration', 'MeanComplexTextDuration', 'TotalPosterOpenDuration',\n",
    "                    'MeanPosterOpenDuration', 'TotalScanningDuration', 'MeanScanningDuration', \n",
    "                    'TotalDiagnosisWorksheetDuration', 'MeanDiagnosisWorksheetDuration',\n",
    "                    'TotalDialogSelections', 'TotalComplexTextOpens', 'TotalPostersOpens', 'TotalScans',\n",
    "                    'TotalDiagnosisWorksheetOpens', 'TotalBackpackOpens']\n",
    "\n",
    "# Order of columns in reflect data csv file\n",
    "reflect_columns = ['StudentId', 'Instance', 'PromptId', 'GameTime(sec)',\n",
    "                  'QuestionId', 'Response', 'ReflectionRating1', 'ReflectionRating2',\n",
    "                  'ReflectionRatingAvg', 'PreTestScore', 'PostTestScore', \n",
    "                  'NormalizedLearningGain', 'NLG_revised']\n",
    "\n",
    "events_without_movement = ['Conversation', 'BooksAndArticles', 'Worksheet', 'Prompts', 'PlotPoint',\n",
    "                           'Posters', 'Scanner', 'WorksheetSubmit']\n",
    "\n",
    "plot_names = ['IntroFromKim', 'TutorialComplete', 'CompletedGOT', 'TalkedToBryce', \n",
    "              'SecondaryPatientSymptoms', 'TalkedToQuentin', 'LearnFoodHistory', \n",
    "              'TalkedToElise', 'TestObject', 'TalkedToTheresa', 'PrimaryPatientSymptoms', \n",
    "              'TalkedToSam', 'TalkedToGreg', 'TestContaminatedObject', 'SubmittedDiagnosis', \n",
    "              'TalkedToRobert', 'LearnAboutBacteria', 'SolvedMystery', 'TalkedToFord', \n",
    "              'LearnAboutViruses'] \n",
    "\n",
    "fewer_plot_names = ['SecondaryPatientSymptoms', 'LearnFoodHistory', \n",
    "                    'TestObject', 'PrimaryPatientSymptoms', \n",
    "                    'TestContaminatedObject', 'SubmittedDiagnosis', \n",
    "                    'SolvedMystery', 'TalkedToElise', 'LearnAboutBacteria', \n",
    "                    'LearnAboutViruses']\n",
    "\n",
    "locations = ['Dock', 'BeachWindTurbineSide', 'BeachHut', 'BeachFirePitSide', 'OutsidePathFromBeach',\n",
    "             'OutsideCenterOfCamp', 'InfirmaryStairs', 'Infirmary', 'DormStairs', 'DormBedArea',\n",
    "             'DormFemaleSittingArea', 'DormMaleSittingArea', 'BryceQuartersStairs',\n",
    "             'BryceQuartersFrontPorch', 'BryceQuartersHall', 'BryceQuartersSittingRoom',\n",
    "             'BryceQuartersBedroom', 'BryceQuartersOffice', 'BryceQuartersBackPorch',\n",
    "             'DiningHallStairs', 'DiningHallTableArea', 'LabStairs', 'Lab', 'DiningHallKitchen']\n",
    "\n",
    "locn_coord_map = {'BeachHut': [264, 380], 'BeachFirePitSide': [80, 380],\n",
    "                  'Infirmary': [40, 185], 'DormFemaleSittingArea': [74, 84], \n",
    "                  'DormBedArea': [74, 82], 'DormMaleSittingArea': [74, 80], \n",
    "                  'BryceQuartersSittingRoom': [213, 78], 'BryceQuartersHall': [213, 80], \n",
    "                  'BryceQuartersBedroom': [213, 82], 'BryceQuartersOffice': [215, 80], \n",
    "                  'DiningHallTableArea': [252, 204], 'Lab': [58, 284], \n",
    "                  'DiningHallKitchen': [254, 204], 'BeachWindTurbineSide': [222, 336],\n",
    "                  'OutsideCenterOfCamp': [175, 185], 'OutsidePathFromBeach': [148, 315], \n",
    "                  'InfirmaryStairs': [42, 185], 'BryceQuartersBackPorch': [217, 80], \n",
    "                  'DormStairs': [76, 82], 'LabStairs': [60, 284], 'DiningHallStairs': [248, 204], \n",
    "                  'Dock': [166, 390], 'BryceQuartersStairs': [209, 80], 'BryceQuartersFrontPorch':[211, 80]}\n",
    "\n",
    "label_goal_locations = {'SecondaryPatientSymptoms': 'BryceQuartersBedroom', \n",
    "                        'LearnFoodHistory': 'DiningHallTableArea', \n",
    "                        'TestObject': 'Lab', 'PrimaryPatientSymptoms': 'Infirmary', \n",
    "                        'TestContaminatedObject': 'Lab', 'SubmittedDiagnosis': 'Infirmary', \n",
    "                        'SolvedMystery': 'Infirmary', 'TalkedToElise': 'Lab', \n",
    "                        'LearnAboutBacteria': 'DormMaleSittingArea', \n",
    "                        'LearnAboutViruses': 'DormMaleSittingArea'}\n",
    "\n",
    "filenames = {2018:\"Datasets/EventSequence2018.csv\", 2019:\"Datasets/EventSequence2019.csv\"}\n",
    "\n",
    "summary_filenames = {2018:\"Datasets/ActivitySummary2018.csv\", 2019:\"Datasets/ActivitySummary2019.csv\"}\n",
    "\n",
    "# Reflection data csv filename\n",
    "reflect_file = 'Datasets/LabeledReflections.csv'\n",
    "\n",
    "elmo_module_locn = \"module/module_elmo2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_elmo2(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.compat.v1.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.compat.v1.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "\n",
    "elmo = hub.load(elmo_module_locn)\n",
    "embed_fn = embed_elmo2(elmo_module_locn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, pca=None, pca_dim=32):\n",
    "    if text != \"\": # string not blank\n",
    "        embeddings = elmo.signatures['default'](tf.convert_to_tensor([text]))[\"elmo\"]\n",
    "    else: # return default embedding\n",
    "        if pca == None: \n",
    "            return [random.uniform(-1,1) for i in range(emb_dim)]\n",
    "        return [random.uniform(-1,1) for i in range(pca_dim)]\n",
    "    \n",
    "    x = embed_fn([text]) # get elmo embedding of string (sentence-level)\n",
    "    embed = x[0].tolist() # there will be only one vector (like, [[vector]]), get rid of extra\n",
    "                          # dimension\n",
    "    if pca == None: # if no PCA model is provided, return embedding directly\n",
    "        return embed\n",
    "    \n",
    "    return pca.transform([embed])[0] # transform embedding and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(s_id, study_number):\n",
    "    pretest, posttest = -1, -1 # entries with pretest/posttest -1 are ignored in final dataset\n",
    "    student_found = False\n",
    "    \n",
    "    for study in summary_filenames:\n",
    "        with open(summary_filenames[study]) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                if row[activity_columns.index('TestSubject')] == s_id:\n",
    "                    student_found = True\n",
    "                    pretest_txt = row[activity_columns.index('PreTestScore')]\n",
    "                    posttest_txt = row[activity_columns.index('PostTestScore')]\n",
    "                    if pretest_txt != \"\" and posttest_txt != \"\":\n",
    "                        pretest = float(pretest_txt)\n",
    "                        posttest = float(posttest_txt)\n",
    "                        break\n",
    "        if student_found:\n",
    "            break\n",
    "                    \n",
    "    return pretest, posttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_rating(s_id, response_number):\n",
    "    next_rating = -1 # entries with next rating -1 are ignored in final dataset\n",
    "    prev_response = \"\"\n",
    "    prev_rating = -1\n",
    "    \n",
    "    with open(reflect_file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            id_idx = reflect_columns.index('StudentId')\n",
    "            instance_idx = reflect_columns.index('Instance')\n",
    "            response_idx = reflect_columns.index('Response')\n",
    "            rating_idx = reflect_columns.index('ReflectionRatingAvg')\n",
    "            if row[id_idx] == s_id and float(row[instance_idx]) == response_number + 1:\n",
    "                next_rating = row[rating_idx]\n",
    "            elif row[id_idx] == s_id and float(row[instance_idx]) == response_number:\n",
    "                prev_response = row[response_idx]\n",
    "                prev_rating = row[rating_idx]\n",
    "                \n",
    "    return next_rating, prev_response, prev_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_goal(s_id, prev_goals, study=2018):\n",
    "    next_goal = -1\n",
    "    \n",
    "    with open(filenames[study]) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            test_id = row[columns.index('TestSubject')]\n",
    "            event = row[columns.index('Event')]\n",
    "            plot = row[columns.index('Name')]\n",
    "            if test_id == s_id and event == 'PlotPoint' and plot in fewer_plot_names and plot not in prev_goals:\n",
    "                next_goal = plot\n",
    "                break\n",
    "    \n",
    "    return next_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs(s_id, data_row, prev_log, pca=None, pca_dim=32, study=2018, tutorial_complete=False):\n",
    "    log = {}\n",
    "    \n",
    "    event_vec = [0 for e in range(len(events_without_movement))]\n",
    "    goal_vec = [0 for g in range(len(plot_names))]\n",
    "    locn_vec = [0 for l in range(len(locations))]\n",
    "    goal_vec[plot_names.index('IntroFromKim')] = 1\n",
    "    goal_vec[plot_names.index('TutorialComplete')] = 1\n",
    "    emb = [] #[random.uniform(-1,1) for e in range(pca_dim)]\n",
    "    next_rating = -1\n",
    "    next_goal = -1\n",
    "    prev_goals = []\n",
    "    goal_number = 0\n",
    "    response_number = 0\n",
    "    current_locn = -1\n",
    "    current_event = -1\n",
    "    prev_response = \"\"\n",
    "    prev_rating = -1\n",
    "    if prev_log: \n",
    "        # if previous action exists, maintain prev goals, response emb, next rating\n",
    "        # and current response number\n",
    "        goal_vec = deepcopy(prev_log['goal'])\n",
    "        emb = deepcopy(prev_log['response_emb'])\n",
    "        next_rating = deepcopy(prev_log['next_rating'])\n",
    "        next_goal = deepcopy(prev_log['next_goal'])\n",
    "        prev_goals = deepcopy(prev_log['prev_goals'])\n",
    "        response_number = deepcopy(prev_log['response_number'])\n",
    "        goal_number = deepcopy(prev_log['goal_number'])\n",
    "        prev_response = deepcopy(prev_log['prev_response'])\n",
    "        prev_rating = deepcopy(prev_log['prev_rating'])\n",
    "        current_locn = deepcopy(prev_log['current_locn'])\n",
    "        current_event = deepcopy(prev_log['current_event'])\n",
    "    \n",
    "    event_col = columns.index('Event')\n",
    "    if data_row[event_col] in events_without_movement:\n",
    "        event_vec[events_without_movement.index(data_row[event_col])] = 1 # set current event to 1\n",
    "    else:\n",
    "        return {}, tutorial_complete # event is movement, and hence is not added to logs\n",
    "    \n",
    "    try:\n",
    "        locn_vec[locations.index(data_row[columns.index('Location')])] = 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    current_locn = data_row[columns.index('Location')]\n",
    "    current_event = data_row[event_col]\n",
    "    \n",
    "    if data_row[event_col] == 'PlotPoint': # if new goal achieved\n",
    "        plot_col = columns.index('Name')\n",
    "        if data_row[plot_col] in fewer_plot_names:\n",
    "            goal_number += 1\n",
    "            next_goal = get_next_goal(s_id, prev_goals, study=study)\n",
    "            if next_goal != -1:\n",
    "                prev_goals.append(next_goal)\n",
    "        goal_vec[plot_names.index(data_row[plot_col])] = 1 # set new goal to 1\n",
    "        if data_row[plot_col] == 'TutorialComplete':\n",
    "            tutorial_complete = True\n",
    "    if next_goal == -1:\n",
    "        next_goal = get_next_goal(s_id, prev_goals, study=study)\n",
    "        prev_goals.append(next_goal)\n",
    "            \n",
    "    if data_row[event_col] == 'Prompts':\n",
    "        progress_plan_col = columns.index('ProgressPlanSummary')\n",
    "        solution_col = columns.index('SolutionApproachSummary')\n",
    "        diff_solution_col = columns.index('DifferentProblemApproachSummary')\n",
    "        # combine all response types to construct response\n",
    "        response = data_row[progress_plan_col] + data_row[solution_col] + data_row[diff_solution_col]\n",
    "        emb.append(get_embedding(response, pca=pca, pca_dim=pca_dim))\n",
    "        response_number += 1 # update current response count for student\n",
    "        next_rating, prev_response, prev_rating = get_next_rating(s_id, response_number) # get response rating for next response\n",
    "    elif next_rating == -1:\n",
    "        next_rating, prev_response, prev_rating = get_next_rating(s_id, response_number) # get response rating for next response\n",
    "    \n",
    "    if prev_log:\n",
    "        log['event'] = [a + b for a, b in zip(prev_log['event'], event_vec)] # event vector is a count vec\n",
    "        log['locn'] = [a + b for a, b in zip(prev_log['locn'], locn_vec)] # event vector is a count vec\n",
    "    else:\n",
    "        log['event'] = event_vec\n",
    "        log['locn'] = locn_vec\n",
    "        \n",
    "    log['goal'] = deepcopy(goal_vec)\n",
    "    log['response_emb'] = deepcopy(emb)\n",
    "    log['next_rating'] = deepcopy(next_rating)\n",
    "    log['next_goal'] = deepcopy(next_goal)\n",
    "    log['prev_goals'] = deepcopy(prev_goals)\n",
    "    log['response_number'] = deepcopy(response_number)\n",
    "    log['goal_number'] = deepcopy(goal_number)\n",
    "    log['current_locn'] = deepcopy(current_locn)\n",
    "    log['prev_response'] = deepcopy(prev_response)\n",
    "    log['prev_rating'] = deepcopy(prev_rating)\n",
    "    log['current_event'] = deepcopy(current_event)\n",
    "    \n",
    "    return log, tutorial_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_model(pca_dim):\n",
    "    pca = PCA(pca_dim)\n",
    "    \n",
    "    responses = []\n",
    "    with open(reflect_file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for i,row in enumerate(csv_reader): # for each written response in LabeledReflections file\n",
    "            if i == 0: # ignore column headers\n",
    "                continue\n",
    "            idx = reflect_columns.index('Response') # get column index of response\n",
    "            if row[idx] != \"\": # if response exists (not blank)\n",
    "                responses.append(get_embedding(row[idx])) # append ELMo embedding\n",
    "    \n",
    "    pca.fit(responses)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_logs(pca_dim=32, movement=False):\n",
    "    # get PCA model for response embeddings\n",
    "    pca = get_pca_model(pca_dim)\n",
    "    \n",
    "    data = {} # dictionary to store student logs [Key: StudentID]\n",
    "    \n",
    "    for study in filenames: # study: 2018/2019\n",
    "        with open(filenames[study]) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row_idx, row in enumerate(csv_reader):\n",
    "                if row_idx == 0: # skip header\n",
    "                    continue\n",
    "                \n",
    "                s_id = row[columns.index('TestSubject')] # ID of current student\n",
    "                if s_id not in data: # add student to dictionary\n",
    "                    data[s_id] = {}\n",
    "                    pretest, posttest = get_scores(s_id, study)\n",
    "                    data[s_id]['pretest'] = pretest\n",
    "                    data[s_id]['posttest'] = posttest\n",
    "                    data[s_id]['tutorial_complete'] = False\n",
    "                    data[s_id]['logs'] = [] # no actions logged yet\n",
    "                    \n",
    "                if len(data[s_id]['logs']) > 0: # has previous actions logged\n",
    "                    prev_log = data[s_id]['logs'][len(data[s_id]['logs'])-1] # pick last action\n",
    "                else:\n",
    "                    prev_log = {} # no available previous action\n",
    "                log, data[s_id]['tutorial_complete'] = get_logs(s_id, row, prev_log, pca=pca, \n",
    "                                                                pca_dim=pca_dim, study=study,\n",
    "                                                                tutorial_complete=data[s_id]['tutorial_complete'])\n",
    "                if log and data[s_id]['tutorial_complete'] and log['next_goal'] != -1: # not a movement event\n",
    "                    data[s_id]['logs'].append(log) # add new action (format: dict) to logs\n",
    "                        \n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
