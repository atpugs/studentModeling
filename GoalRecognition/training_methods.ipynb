{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from build_models import *\n",
    "from evaluation import performance_test_CV\n",
    "from bias_inspection import get_protected_attr\n",
    "from bias_mitigation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_students(data):\n",
    "    filtered_data = {}\n",
    "    for s_id in data:\n",
    "        if not(data[s_id]['pretest'] == -1 or data[s_id]['posttest'] == -1):\n",
    "            # add to filtered set if pretest/posttest information is present\n",
    "            filtered_data[s_id] = deepcopy(data[s_id])\n",
    "            \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(data, ids):\n",
    "    filtered_data = {}\n",
    "    for s_id in data:\n",
    "        if s_id in ids:\n",
    "            filtered_data[s_id] = deepcopy(data[s_id])\n",
    "            \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(data, split=12):\n",
    "    copy_data = deepcopy(data)\n",
    "    \n",
    "    student_ids = np.array([s_id for s_id in copy_data])\n",
    "    ids_train, ids_test = train_test_split(student_ids, test_size=0.20, random_state=split)\n",
    "    \n",
    "    train_data = get_set(copy_data, ids_train)\n",
    "    test_data = get_set(copy_data, ids_test)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_data, val_data, get_required_model, epochs=50, split=12, folds=5, seq_length=20,\n",
    "              monitor='val_loss', baseline=False, model_unique_filename=\"\"):\n",
    "    \n",
    "    # pack data to send for preprocessing\n",
    "    raw_data = {'Train': train_data, \n",
    "                'Val': val_data, \n",
    "                'Test': deepcopy(val_data)}\n",
    "        \n",
    "    # get model and preprocessed data and labels according to the required model \n",
    "    model, data, labels, ids = get_required_model(raw_data, seq_length=seq_length)\n",
    "        \n",
    "    # unpack data to get train, test and validation data/labels/ids\n",
    "    train_set, val_set = data['Train'], data['Val']\n",
    "    train_labels, val_labels = labels['Train'], labels['Val']\n",
    "    train_ids, val_ids = ids['Train'], ids['Val']\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    # Save best model (refer monitor criterion) here using early stopping\n",
    "    model_filename = 'model_overall_'+model_unique_filename+'.h5'\n",
    "        \n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "            \n",
    "    callbacks = [EarlyStopping(monitor=monitor, patience=10), ModelCheckpoint(model_filename,\n",
    "                                                                              save_best_only=True, \n",
    "                                                                              save_weights_only=False)]\n",
    "        \n",
    "    # Train model\n",
    "    history = model.fit(data['Train'], labels['Train'], validation_data=(data['Val'], labels['Val']),\n",
    "                        epochs=epochs, verbose=1, callbacks=callbacks, shuffle=True)\n",
    "        \n",
    "    try:\n",
    "        model_trained = load_model(model_filename)\n",
    "        train_pred = model_trained.predict(data['Train'])\n",
    "        val_pred = model_trained.predict(data['Val'])\n",
    "    except:\n",
    "        train_pred = model.predict(data['Train'])\n",
    "        val_pred = model.predict(data['Val'])\n",
    "            \n",
    "    clear_session()\n",
    "        \n",
    "    train_results = performance_test_CV(data['Train'], train_pred, labels['Train'], train_ids, \"TRAIN\",\n",
    "                                        seq_length=seq_length, extension=extension)\n",
    "    val_results = performance_test_CV(data['Val'], val_pred, labels['Val'], val_ids, \"VAL\",\n",
    "                                      seq_length=seq_length, extension=extension)\n",
    "        \n",
    "    print(\"TRAIN SET: \", train_results)\n",
    "    print(\"VAL SET: \", val_results)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_counts(data, protected_label, value, set_name):\n",
    "    instance = 0\n",
    "    for s_id in data:\n",
    "        if data[s_id][protected_label] == str(value):\n",
    "            instance += 1\n",
    "            \n",
    "    print(\"Set name: \", set_name, \"\\tProtected_attr: \", protected_label, \"\\tValue: \", value)\n",
    "    print(\"Instance_count: \", instance, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(copy_data, set_name):\n",
    "    data = get_protected_attr(deepcopy(copy_data), protected_label=\"Gender\")\n",
    "    get_instance_counts(data, protected_label=\"Gender\", value=1, set_name=set_name)\n",
    "    get_instance_counts(data, protected_label=\"Gender\", value=2, set_name=set_name)\n",
    "    \n",
    "    data = get_protected_attr(deepcopy(copy_data), protected_label=\"Prior_exp\")\n",
    "    get_instance_counts(data, protected_label=\"Prior_exp\", value=1, set_name=set_name)\n",
    "    get_instance_counts(data, protected_label=\"Prior_exp\", value=2, set_name=set_name)\n",
    "    get_instance_counts(data, protected_label=\"Prior_exp\", value=3, set_name=set_name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_CV(inp_data, get_required_model, epochs=50, split=12, folds=5, seq_length=20,\n",
    "                 monitor='val_loss', baseline=False, model_unique_filename=\"\", extension=\"\", \n",
    "                 bias_mitigation=False):\n",
    "    copy_data = deepcopy(inp_data)\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=split)\n",
    "    fold = 0\n",
    "    student_ids = np.array([s_id for s_id in copy_data])\n",
    "    ratings = {'correct': [], 'incorrect': []}\n",
    "    \n",
    "    for train_index, test_index in kf.split(student_ids):\n",
    "        ids_train, ids_test = student_ids[train_index], student_ids[test_index]\n",
    "        ids_train, ids_val = train_test_split(ids_train, test_size=0.20, random_state=split)\n",
    "        \n",
    "        #if fold == 1:\n",
    "        #    get_stats(get_set(copy_data, ids_train), set_name=\"Train\")\n",
    "        #    get_stats(get_set(copy_data, ids_val), set_name=\"Val\")\n",
    "        \n",
    "        # pack data to send for preprocessing\n",
    "        raw_data = {'Train': get_set(copy_data, ids_train), \n",
    "                    'Val': get_set(copy_data, ids_val), \n",
    "                    'Test': get_set(copy_data, ids_test)}\n",
    "        \n",
    "        # get model and preprocessed data and labels according to the required model \n",
    "        model, data, labels, ids = get_required_model(raw_data, seq_length=seq_length)\n",
    "        \n",
    "        # unpack data to get train, test and validation data/labels/ids\n",
    "        train_set, val_set, test_set = data['Train'], data['Val'], data['Test']\n",
    "        train_labels, val_labels, test_labels = labels['Train'], labels['Val'], labels['Test']\n",
    "        train_ids, val_ids, test_ids = ids['Train'], ids['Val'], ids['Test']\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        # Save best model (refer monitor criterion) here using early stopping\n",
    "        model_filename = 'model_' + model_unique_filename + 'cv' + str(fold) + '.h5'\n",
    "        \n",
    "        if os.path.exists(model_filename):\n",
    "            os.remove(model_filename)\n",
    "            \n",
    "        callbacks = [EarlyStopping(monitor=monitor, patience=10), ModelCheckpoint(model_filename,\n",
    "                                                                                  save_best_only=True, \n",
    "                                                                                  save_weights_only=False)]\n",
    "        \n",
    "        #check_dimensions(data['Train'][0][0])\n",
    "        # Train model\n",
    "        history = model.fit(data['Train'], labels['Train'], validation_data=(data['Val'], labels['Val']),\n",
    "                            epochs=epochs, verbose=1, callbacks=callbacks, shuffle=True)\n",
    "        \n",
    "        try:\n",
    "            model_trained = load_model(model_filename)\n",
    "            train_pred = model_trained.predict(data['Train'])\n",
    "            val_pred = model_trained.predict(data['Val'])\n",
    "            test_pred = model_trained.predict(data['Test'])\n",
    "        except:\n",
    "            train_pred = model.predict(data['Train'])\n",
    "            val_pred = model.predict(data['Val'])\n",
    "            test_pred = model.predict(data['Test'])\n",
    "            \n",
    "        clear_session()\n",
    "        \n",
    "        train_results = performance_test_CV(data['Train'], train_pred, labels['Train'], train_ids, \"TRAIN\",\n",
    "                                            seq_length=seq_length, extension=extension)\n",
    "        val_results = performance_test_CV(data['Val'], val_pred, labels['Val'], val_ids, \"VAL\",\n",
    "                                            seq_length=seq_length, extension=extension)\n",
    "        test_results, ratings_test = performance_test_CV(data['Test'], test_pred, labels['Test'], test_ids, \"TEST\",\n",
    "                                            seq_length=seq_length, extension=extension)\n",
    "        \n",
    "        print(\"FOLD: \", fold)\n",
    "        print(\"TRAIN SET: \", train_results)\n",
    "        print(\"VAL SET: \", val_results)\n",
    "        print(\"TEST SET: \", test_results)\n",
    "        \n",
    "        ratings['correct'].extend(ratings_test['correct'])\n",
    "        ratings['incorrect'].extend(ratings_test['incorrect'])\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    print(ratings)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(ratings.values())\n",
    "    ax.set_xticklabels(ratings.keys())\n",
    "    plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimensions(data, desired=60):\n",
    "    for d in data:\n",
    "        print(len(d))\n",
    "            \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
